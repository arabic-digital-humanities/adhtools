{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results are different for other analyzer\n",
    "# TODO: make sure we have sentence boundaries\n",
    "fp = '/media/sf_VBox_Shared/Arabic/Abdelhaq/processed/IbnCabidin1252.txt_results_Alkhalil.xml'\n",
    "with open(fp) as f:\n",
    "    safar_el = etree.parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for w in safar_el.iter('word'):\n",
    "    word_id = w.attrib['w_id']\n",
    "    word_value = w.attrib['value']\n",
    "    a_dict = [a.attrib for a in w.iter('analysis')]\n",
    "    w_df = pd.DataFrame.from_records([dict(a_list) for a_list in a_dict])\n",
    "    w_df['w_id'] = word_id\n",
    "    df = df.append(w_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['w_id'] = df['w_id'].astype('int')\n",
    "df['a_id'] = df['a_id'].astype('int')\n",
    "df = df.set_index(['w_id', 'a_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many values we have for each field\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'caze' indicates whether a noun is defined (a ball vs the ball)\n",
    "df['caze'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many different roots per word\n",
    "df.groupby('w_id')['root'].nunique().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many different stems per word\n",
    "df.groupby('w_id')['stem'].nunique().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The type is noun, verb etc but can be quite specific. Does not contain gender, number etc\n",
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make a tab separated file with the following 10 columns:\n",
    "* Token number (resets every sentence)\n",
    "* Token\n",
    "* Lemma (according to MBLEM)\n",
    "* Morphological segmentation (according to MBMA)\n",
    "* PoS tag (CGN tagset; according to MBT)\n",
    "* Confidence in the POS tag, a number between 0 and 1, representing the probability mass assigned to the best guess tag in the tag distribution\n",
    "* Named entity type, identifying person (PER), organization (ORG), location (LOC), product (PRO), event (EVE), and miscellaneous (MISC), using a BIO (or IOB2) encoding\n",
    "* Base (non-embedded) phrase chunk in BIO encoding\n",
    "* Token number of head word in dependency graph (according to CSI-DP)\n",
    "* Type of dependency relation with head word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_in = '/media/sf_VBox_Shared/Arabic/Fiqh/Fiqh-Alkhalil-csv/csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses_roots = set('''سمع\n",
    "بصر\n",
    "لمس \n",
    "شمم\n",
    "ذوق'''.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the XML files\n",
    "# metadata = []\n",
    "# matched_words = []\n",
    "# for dirname in os.listdir(fp_in):\n",
    "#     sub_dir = os.path.join(fp_in, dirname)\n",
    "#     for filename in os.listdir(sub_dir)[5:7]:\n",
    "#         with open(os.path.join(sub_dir, filename)) as fn:\n",
    "#             xml_data = BeautifulSoup(fn, 'xml')\n",
    "#             meta_dict = {meta['name']: meta.text.strip() for meta in xml_data.metadata.find_all('meta')}\n",
    "#             meta_dict['Bookname'] = dirname\n",
    "#             meta_dict['Filename'] = filename\n",
    "#             metadata.append(meta_dict)\n",
    "\n",
    "#             # loop over words and match with the searched words\n",
    "#             for word in xml_data.morphology_analysis.find_all('word'):\n",
    "#                 roots = set([a.get('root', '') for a in word.find_all('analysis')])\n",
    "#                 if not senses_roots.isdisjoint(roots):\n",
    "#                     matched_words.append((filename, word.attrs, [a.attrs for a in word.find_all('analysis')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matched_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Put all results in a dataframe\n",
    "# df_total = pd.DataFrame()\n",
    "# for filename, word_dict, analyses in matched_words:\n",
    "#     df_analyses = pd.DataFrame(analyses)\n",
    "#     df_analyses['Filename'] = filename\n",
    "#     for att in word_dict:\n",
    "#         df_analyses[att] = word_dict[att]\n",
    "#     df_total = df_total.append(df_analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df = pd.DataFrame(metadata).set_index('Filename')\n",
    "# metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the csv files\n",
    "df_total = pd.DataFrame()\n",
    "for filename in os.listdir(fp_in):\n",
    "    df_sub = pd.read_csv(os.path.join(fp_in, filename), index_col=0)\n",
    "    df_sub = df_sub[df_sub.root.isin(senses_roots)]\n",
    "    df_total = df_total.append(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.root.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.word.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the words, what is the number of roots?\n",
    "df_total.groupby('word').nunique()['root'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with newer meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fields = ['BookURI', 'Century', 'AuthorNAME', 'AuthorGeographicalArea', 'AuthorBORNH', 'AuthorBORNC', 'AuthorDIEDH', 'AuthorDIEDC',  'BookSUBJ', 'NumberOfTokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_new = pd.read_csv('/media/sf_VBox_Shared/Arabic/Fiqh/merged_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_new['Bookname'] = metadata_new.filename_old.str.extract('(.*)\\.txt', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata_merged = metadata_df['Bookname'].reset_index().merge(metadata_new, left_on='Bookname', right_on='Bookname', how='left')\n",
    "metadata_merged = metadata_new[['Bookname']+metadata_fields].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.shape, metadata_new.shape, metadata_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the analyses with the roots that we are interested in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dict = {s['root']: s['tr_root'] for i, s in df_total[['root', 'tr_root']].drop_duplicates().iterrows()}\n",
    "tr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_total.merge(metadata_merged, left_on='title', right_on='Bookname', how='left').drop(['Bookname', 'title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('/media/sf_VBox_Shared/Arabic/Analyses/senses_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also prepare aggregated csv\n",
    "df_agg = df_total.groupby(['title', 'root']).size().unstack(fill_value=0)\n",
    "df_agg.columns = [u'{} ({})'.format(c, tr_dict[c]) for c in df_agg.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_merged = df_agg.reset_index().merge(metadata_merged, left_on='title', right_on='Bookname', how='left').drop(['Bookname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses_cols = df_agg.columns\n",
    "df_agg_merged[senses_cols] = df_agg_merged.apply(lambda r: r[senses_cols]/r['NumberOfTokens'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_merged.to_csv('/media/sf_VBox_Shared/Arabic/Analyses/senses_agg_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cast_year(val):\n",
    "    try:\n",
    "        return int(str(val).split('-')[0])\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "df_agg_merged['AuthorDIEDC_int'] = df_agg_merged.AuthorDIEDC.apply(cast_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_merged[senses_cols].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1)\n",
    "colors = ['lightgreen', 'yellow', 'black', 'red']\n",
    "for i in range(len(senses_cols)):\n",
    "    df_agg_merged.plot('AuthorDIEDC_int', senses_cols[i], kind='scatter', ax=axes, c=colors[i], label=senses_cols[i])\n",
    "\n",
    "axes.set_ylim(0, 0.0022)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in senses_cols:\n",
    "    ax = df_agg_merged.boxplot(col, by='AuthorGeographicalArea')\n",
    "    ax.set_title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTF encoding stuff\n",
    "arab_text = 'سمع'\n",
    "latin_text = 'smE'\n",
    "ltr_char = '\\u200E'\n",
    "rtl_char = '\\u061C'\n",
    "text1 = '{}: ({})'.format(arab_text, latin_text)\n",
    "text2 = '{}{}{}: ({})'.format(rtl_char, arab_text, ltr_char, latin_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text1)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2)\n",
    "axes[0,0].set_title(latin_text)\n",
    "axes[1,0].set_title(arab_text)\n",
    "axes[0,1].set_title(text1)\n",
    "axes[1,1].set_title(text2)\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[i,j].set_xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "# load search terms\n",
    "# make regex\n",
    "# save resuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh', 'matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get search terms\n",
    "terms_file = '/home/jvdzwaan/Downloads/Farad_Infixes (1).txt'\n",
    "with open(terms_file, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "terms = [t.strip() for t in lines]\n",
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "text_file = '/home/jvdzwaan/code/fiqh_corpus/0483IbnAhmadSarakhsi.Mabsut.txt'\n",
    "with open(text_file, encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(terms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#regex = r'(.+\\s){0,5}.*فرض.*(.+\\s){0,5}'\n",
    "\n",
    "for match in re.finditer(r'\\S'+terms[0]+'\\S', text):\n",
    "    #print(match.span())\n",
    "    b, e = match.span()\n",
    "    if b < 25:\n",
    "        b = 0\n",
    "    else:\n",
    "        b = b-25\n",
    "    if e > len(text) - 25:\n",
    "        e = len(text)\n",
    "    else:\n",
    "        e = e + 27\n",
    "    print(text[b:e])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "\n",
    "for t in terms:\n",
    "    regexes = [r'\\S'+t+'\\S', r'\\s'+t+'\\S', r'\\S'+t+'\\s']\n",
    "    for regex in regexes:\n",
    "        print(regex)\n",
    "        for match in re.finditer(r'\\S'+terms[0]+'\\S', text):\n",
    "            b, e = match.span()\n",
    "            if b < 25:\n",
    "                b = 0\n",
    "            else:\n",
    "                b = b-25\n",
    "            if e > len(text) - 25:\n",
    "                e = len(text)\n",
    "            else:\n",
    "                e = e + 27\n",
    "            context = text[b:e]\n",
    "            results.append({'term': t, 'context': context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('0483IbnAhmadSarakhsi.Mabsut-farad_infix_matches.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlppln.utils import get_files\n",
    "\n",
    "in_dir = '/home/jvdzwaan/data/adh-corpora/fiqh_corpus/txt/'\n",
    "corpus = get_files(in_dir)\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from nlppln.utils import remove_ext, get_files\n",
    "\n",
    "from adhtools.utils import analyzer_xml2df\n",
    "\n",
    "def text_regex(fname, term):\n",
    "    with open(fname) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    num_matches1 = 0\n",
    "    for match in re.finditer(r'\\b.?'+term+r'.?\\b', text):\n",
    "        num_matches1 += 1\n",
    "    \n",
    "    num_matches2 = 0\n",
    "    for match in re.finditer(term, text):\n",
    "        num_matches2 += 1\n",
    "    \n",
    "    return num_matches1, num_matches2\n",
    "\n",
    "def text_results(in_files, term):\n",
    "    res = []\n",
    "    for in_file in tqdm(in_files):\n",
    "        res.append(text_regex(in_file, term))\n",
    "    return res\n",
    "\n",
    "def xml_regex(fname, term):\n",
    "    #print(fname)\n",
    "    data = analyzer_xml2df(fname)\n",
    "    #print(data)\n",
    "    words = data['word']\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    #print(len(text))\n",
    "    \n",
    "    regex = re.compile(r'\\b.?'+term+r'.?\\b')\n",
    "    \n",
    "    num_matches1 = 0\n",
    "    for match in re.finditer(regex, text):\n",
    "        num_matches1 += 1\n",
    "        \n",
    "    num_matches2 = 0\n",
    "    for match in re.finditer(term, text):\n",
    "        num_matches2 += 1\n",
    "\n",
    "    return num_matches1, num_matches2\n",
    "\n",
    "def xml_results(in_files, term):\n",
    "    res = []\n",
    "    for in_file in tqdm(in_files):\n",
    "        res.append(xml_regex(in_file, term))\n",
    "    return res\n",
    "\n",
    "def count_matches(in_dir_text, in_dir_xml, term):\n",
    "    result = pd.DataFrame()\n",
    "    in_files = get_files(in_dir_text)\n",
    "    text_res = text_results(in_files, term) \n",
    "    result['text'] = [a for a, b in text_res]\n",
    "    result['text2'] = [b for a, b in text_res]\n",
    "    \n",
    "    in_files = get_files(in_dir_xml)\n",
    "    xml_res = xml_results(in_files, term) \n",
    "    result['xml'] = [a for a, b in xml_res]\n",
    "    result['xml2'] = [b for a, b in xml_res]\n",
    "    \n",
    "    index = [remove_ext(fname) for fname in in_files]\n",
    "    result['idx'] = index\n",
    "    result = result.set_index('idx')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data2 = count_matches('/home/jvdzwaan/data/adh-corpora/fiqh_corpus/txt/', \n",
    "                      '/home/jvdzwaan/data/tmp/adh/2018-11-07-fiqh-alkhalil/', \n",
    "                      'مصلح')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.plot(kind='bar', figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[['text', 'text2']].plot(figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['text2'] == data2['xml2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.loc['1266MuhammadHasanNajafiJawhari.JawahirKalam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query by inserting keyword\n",
    "# get url\n",
    "# check status code\n",
    "# read xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "term = 'مصلح'\n",
    "url = 'http://localhost:8080/blacklab-server/Fiqh/hits'\n",
    "params = {'patt': '\".*{}.*\"'.format(term), 'number': 100, 'group': 'field:BookURI'}\n",
    "\n",
    "r = requests.get(url, params=params)\n",
    "print(r.url)\n",
    "print(r.status_code)\n",
    "#print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'xml')\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noh = soup.find('numberOfHits')\n",
    "print(noh.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgs = soup.find_all('hitgroup')\n",
    "result = {}\n",
    "for hg in hgs:\n",
    "    #print(hg)\n",
    "    name = hg.identityDisplay.text\n",
    "    value = int(hg.size.text)\n",
    "    result[name] = value\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['blacklab'] = pd.Series(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['blacklab'] == data2['xml2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[data2['blacklab'] != data2['xml2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[['blacklab', 'xml2']].plot(figsize=(15,8), kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir_xml = '/home/jvdzwaan/data/tmp/adh/2018-11-07-fiqh-alkhalil/'\n",
    "in_files = get_files(in_dir_xml)\n",
    "index = [remove_ext(fname) for fname in in_files]\n",
    "print(index)\n",
    "data1['idx'] = index\n",
    "data1 = data1.set_index('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#xml_files = get_files('/home/jvdzwaan/data/tmp/adh/2018-11-07-fiqh-alkhalil')\n",
    "#for in_file in xml_files:\n",
    "#    print(in_file)\n",
    "\n",
    "def xml_regex(fname, term):\n",
    "    #print(fname)\n",
    "    data = analyzer_xml2df(fname)\n",
    "    #print(data)\n",
    "    words = data['word']\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    print(len(text))\n",
    "    \n",
    "    regex = re.compile(r'\\b.?'+term+r'.?\\b')\n",
    "    \n",
    "    num_matches1 = 0\n",
    "    for match in re.finditer(regex, text):\n",
    "        num_matches1 += 1\n",
    "        \n",
    "    num_matches2 = 0\n",
    "    for word in words:\n",
    "        if re.search(term, word):\n",
    "            num_matches2 += 1\n",
    "\n",
    "    return num_matches1, num_matches2\n",
    "\n",
    "r = xml_regex('/home/jvdzwaan/data/tmp/adh/2018-11-07-fiqh-alkhalil/0179MalikIbnAnas.Muwatta.xml', 'مصالح')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xml_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = analyzer_xml2df('/home/jvdzwaan/data/tmp/adh/2018-11-07-fiqh-alkhalil/0179MalikIbnAnas.Muwatta.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = r['word']\n",
    "text = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "term = 'مصلح'\n",
    "num_matches = 0\n",
    "for match in re.finditer(r'\\b.*'+term+r'.*\\b', text):\n",
    "    num_matches += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_matches = 0\n",
    "for word in words:\n",
    "    if re.search(term, word):\n",
    "        num_matches += 1\n",
    "print(num_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in_file in corpus:\n",
    "    text_regex(in_file, 'مصالح')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in_file in corpus:\n",
    "    text_regex(in_file, 'قال')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

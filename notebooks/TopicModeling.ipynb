{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import adhtools.utils\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "in_dir = '/media/sf_VBox_Shared/Arabic/Fiqh/2019-01-10-Fiqh-LIGHT10-chapters/'\n",
    "book_files = glob.glob(in_dir, '*.xml')\n",
    "fnames = [os.path.basename(fn) for fn in book_files]\n",
    "print(len(book_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_stopwordlist = '/media/sf_VBox_Shared/Arabic/arabic_stop-words_7-8-2018.txt'\n",
    "external_stopwords = [line.strip() for line in open(path_to_stopwordlist, 'r', encoding='utf-8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = adhtools.utils.corpus_str(book_files, analyzer=False, field='proposed_root')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer( stop_words=external_stopwords, min_df=2, max_df=0.9)\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78526"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ايام', 'ببعد', 'قيد', 'حاشي', 'ورايت', 'توب', 'تقبل', 'ثلاث',\n",
       "       'استتاب', 'نااب', 'ول', 'وقصاص', 'عدل', 'اهل', 'وباغ', 'رد',\n",
       "       'مجمع', 'رتد', 'حا', 'لد', 'زنا', 'ثبوت', 'محصن', 'كز', 'فليحرر',\n",
       "       'كغير', 'نيت', 'صريح', 'قرب', 'يحتاج', 'طاع', 'صح', 'نم', 'صيام',\n",
       "       'يصح', 'عتق', 'كافر', 'ظاهر', 'بذم', 'تبق', 'برا', 'يرج', 'مرض',\n",
       "       'لكبر', 'عجز', 'صوم', 'رقيق', 'كفر', 'جن', 'فصل'], dtype='<U13')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some example words from the first document\n",
    "np.array(feature_names)[X[0].indices][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ول      587\n",
       "اب      452\n",
       "صلا     373\n",
       "اذ      313\n",
       "صل      276\n",
       "زكا     194\n",
       "مال     189\n",
       "بيع     189\n",
       "حج      185\n",
       "حد      183\n",
       "ام      164\n",
       "مالك    157\n",
       "شهاد    125\n",
       "قتل     115\n",
       "عتق     114\n",
       "طلاق    112\n",
       "ارض      96\n",
       "وص       96\n",
       "امام     91\n",
       "غسل      90\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_imp_words = pd.Series(np.array(feature_names)[X.argmax(axis=1)].flatten())\n",
    "most_imp_words.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_topics = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 12107\n",
      "INFO:lda:vocab_size: 78526\n",
      "INFO:lda:n_words: 26487842\n",
      "INFO:lda:n_topics: 60\n",
      "INFO:lda:n_iter: 500\n",
      "INFO:lda:<0> log likelihood: -329962036\n",
      "INFO:lda:<10> log likelihood: -269955058\n",
      "INFO:lda:<20> log likelihood: -241192245\n",
      "INFO:lda:<30> log likelihood: -235990664\n",
      "INFO:lda:<40> log likelihood: -233759236\n",
      "INFO:lda:<50> log likelihood: -232532366\n",
      "INFO:lda:<60> log likelihood: -231771662\n",
      "INFO:lda:<70> log likelihood: -231248755\n",
      "INFO:lda:<80> log likelihood: -230882717\n",
      "INFO:lda:<90> log likelihood: -230569937\n",
      "INFO:lda:<100> log likelihood: -230341985\n",
      "INFO:lda:<110> log likelihood: -230158724\n",
      "INFO:lda:<120> log likelihood: -230002953\n",
      "INFO:lda:<130> log likelihood: -229880099\n",
      "INFO:lda:<140> log likelihood: -229754821\n",
      "INFO:lda:<150> log likelihood: -229615090\n",
      "INFO:lda:<160> log likelihood: -229519526\n",
      "INFO:lda:<170> log likelihood: -229427169\n",
      "INFO:lda:<180> log likelihood: -229329622\n",
      "INFO:lda:<190> log likelihood: -229257073\n",
      "INFO:lda:<200> log likelihood: -229207947\n",
      "INFO:lda:<210> log likelihood: -229123305\n",
      "INFO:lda:<220> log likelihood: -229075595\n",
      "INFO:lda:<230> log likelihood: -229038579\n",
      "INFO:lda:<240> log likelihood: -228969962\n",
      "INFO:lda:<250> log likelihood: -228935108\n",
      "INFO:lda:<260> log likelihood: -228889912\n",
      "INFO:lda:<270> log likelihood: -228841441\n",
      "INFO:lda:<280> log likelihood: -228798340\n",
      "INFO:lda:<290> log likelihood: -228776316\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-21c0ef4b3c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnr_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/adh/lib/python3.7/site-packages/lda/lda.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \"\"\"\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/adh/lib/python3.7/site-packages/lda/lda.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;31m# keep track of loglikelihoods for monitoring convergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikelihoods_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<{}> log likelihood: {:.0f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/adh/lib/python3.7/site-packages/lda/lda.py\u001b[0m in \u001b[0;36m_sample_topics\u001b[0;34m(self, rands)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         lda._lda._sample_topics(self.WS, self.DS, self.ZS, self.nzw_, self.ndz_, self.nz_,\n\u001b[0;32m--> 312\u001b[0;31m                                 alpha, eta, rands)\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lda\n",
    "model = lda.LDA(n_topics=nr_topics, n_iter=500, random_state=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda = LatentDirichletAllocation(n_components=nr_topics, random_state=0, max_iter=50)\n",
    "# document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = model.doc_topic_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_out = '/media/sf_VBox_Shared/Arabic/Analyses/Fiqh_final/topicmodelling/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_document_topics = pd.DataFrame(document_topics, index=fnames)\n",
    "df_document_topics.to_csv(os.path.join(fp_out, 'fiqh_light10_document_topics_{}.csv'.format(nr_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda.components_.shape\n",
    "model.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words = pd.DataFrame(np.argsort(model.components_, axis=1)[:,-10:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words = topic_words.applymap(lambda l: feature_names[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words.to_csv(os.path.join(fp_out, 'fiqh_light10_topics_{}.csv'.format(nr_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adh]",
   "language": "python",
   "name": "conda-env-adh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

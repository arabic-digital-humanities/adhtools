{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "\n",
    "def stemmer_xml2df2(fname):\n",
    "    result = []\n",
    "    \n",
    "    # Extract the words\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('word'))\n",
    "    for event, elem in context:\n",
    "        stem = None\n",
    "        for a in elem.getchildren():\n",
    "            if a.tag == 'analysis':\n",
    "                stem = a.attrib['stem']\n",
    "        result.append({'word': elem.attrib['value'], 'proposed_root': stem})\n",
    "        \n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    \n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "def analyzer_xml2df2(fname):\n",
    "    result = []\n",
    "    \n",
    "    # Extract the words\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('word'))\n",
    "    for event, elem in context:\n",
    "        word = elem.attrib['value']\n",
    "        #print(repr(word))\n",
    "        if word != '':\n",
    "            roots = []\n",
    "            for a in elem.getchildren():\n",
    "                if a.tag == 'analysis':\n",
    "                    try:\n",
    "                        roots.append(a.attrib['root'])\n",
    "                    except:\n",
    "                        pass\n",
    "            roots = list(set(roots))\n",
    "            if len(roots) == 0:\n",
    "                roots.append('NOANALYSIS')\n",
    "            result.append({'word': elem.attrib['value'], 'proposed_root': '\\\\'.join(roots)})\n",
    "        \n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    \n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_analyzer(in_file):\n",
    "    data = analyzer_xml2df2(in_file)\n",
    "    return(list(data['word']))\n",
    "\n",
    "def read_file_stemmer(in_file):\n",
    "    data = stemmer_xml2df2(in_file)\n",
    "    return(list(data['proposed_root']))\n",
    "\n",
    "def corpus(in_files, analyzer=True):\n",
    "\n",
    "    for in_file in in_files:\n",
    "        if analyzer:\n",
    "            ws = read_file_analyzer(in_file)\n",
    "        else:\n",
    "            ws = read_file_stemmer(in_file)\n",
    "        \n",
    "        yield(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maak term/document matrix van 1 boek uit Fiqh met document per chapter\n",
    "\n",
    "import glob\n",
    "\n",
    "book_files = glob.glob('/home/jvdzwaan/data/tmp/adh/2018-10-23-Fiqh-stemmed-chapters/*.xml')\n",
    "book_files.sort()\n",
    "print(len(book_files))\n",
    "print(book_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "c = corpus(book_files, analyzer=False)\n",
    "data = [' '.join(list(terms)) for terms in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def split(string):\n",
    "    return string.split()\n",
    "\n",
    "count_vect = CountVectorizer(input='content', lowercase=False, tokenizer=split)\n",
    "x = count_vect.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.vocabulary_.get(u'غرب')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "x = tfidf_transformer.fit_transform(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "result = cosine_similarity(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# cluster chapters based on affinity propagation\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "af = AffinityPropagation().fit(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "#print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "#print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "#print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "#print(\"Adjusted Rand Index: %0.3f\"\n",
    "#      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "#print(\"Adjusted Mutual Information: %0.3f\"\n",
    "#      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "#print(\"Silhouette Coefficient: %0.3f\"\n",
    "#      % metrics.silhouette_score(X, labels, metric='sqeuclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters_), colors):\n",
    "    class_members = labels == k\n",
    "    cluster_center = result[cluster_centers_indices[k]]\n",
    "    plt.plot(result[class_members, 0], result[class_members, 1], col + '.')\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    for x in result[class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "def find_similar(tfidf_matrix, index, top_n = 5):\n",
    "    cosine_similarities = linear_kernel(tfidf_matrix[index:index+1], tfidf_matrix).flatten()\n",
    "    related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n",
    "    return [(index, cosine_similarities[index]) for index in related_docs_indices][0:top_n]\n",
    "\n",
    "def find_similar_threshold(tfidf_matrix, index, threshold=0.5):\n",
    "    cosine_similarities = linear_kernel(tfidf_matrix[index:index+1], tfidf_matrix).flatten()\n",
    "    related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n",
    "    res = []\n",
    "    for index in related_docs_indices:\n",
    "        sim = cosine_similarities[index]\n",
    "        if sim > threshold:\n",
    "            res.append((index, sim))\n",
    "    return res\n",
    "\n",
    "for idx, sim in find_similar(x, 1, top_n=20):\n",
    "    print(sim, os.path.basename(book_files[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sim in find_similar_threshold(x, 1):\n",
    "    print(sim, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_files[8001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "dist = cosine_distances(x, x)\n",
    "\n",
    "X_embedded = TSNE(n_components=2, metric='precomputed').fit_transform(dist)\n",
    "print(X_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_embedded[:,0], X_embedded[:,1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

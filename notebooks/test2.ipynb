{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Max's words\n",
    "\n",
    "nouns = '/home/jvdzwaan/data/adh/word-lists/farada-noun.txt'\n",
    "verbs = '/home/jvdzwaan/data/adh/word-lists/farada-verb.txt'\n",
    "\n",
    "with open(nouns, encoding='utf-8') as f:\n",
    "    words1 = f.readlines()\n",
    "with open(verbs, encoding='utf-8') as f:\n",
    "    words2 = f.readlines()\n",
    "\n",
    "farada = [w.strip() for w in words1 + words2]\n",
    "len(farada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farada = set(farada)\n",
    "len(farada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from root-extraction-performance.ipynb\n",
    "import codecs\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def stemmer_xml2df(fname):\n",
    "    with codecs.open(fname) as f:\n",
    "        soup = BeautifulSoup(f.read(), 'xml')\n",
    "    \n",
    "    result = []    \n",
    "    for word in soup.find_all('word'):\n",
    "        result.append({'word': word['value'], 'proposed_root': word.analysis['stem']})\n",
    "    \n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "def analyzer_xml2df(fname):\n",
    "    #print(fname)\n",
    "    with codecs.open(fname) as f:\n",
    "        soup = BeautifulSoup(f.read(), 'xml')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for word in soup.find_all('word'):\n",
    "        analyses = word.find_all('analysis')\n",
    "        roots = [a.get('root', 'NO_ROOT') for a in analyses]\n",
    "        roots = list(set(roots))\n",
    "        if len(roots) == 0:\n",
    "            roots.append('NOANALYSIS')\n",
    "        result.append({'word': word['value'], 'proposed_root': '\\\\'.join(roots)})\n",
    "    \n",
    "    #print(len(result))\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "def stemmer_xml2df2(fname):\n",
    "    result = []\n",
    "    \n",
    "    # Extract the words\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('word'))\n",
    "    for event, elem in context:\n",
    "        stem = None\n",
    "        for a in elem.getchildren():\n",
    "            if a.tag == 'analysis':\n",
    "                stem = a.attrib['stem']\n",
    "        result.append({'word': elem.attrib['value'], 'proposed_root': stem})\n",
    "        \n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    \n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stemmed_file = '/home/jvdzwaan/data/tmp/adh/stemmer/0483IbnAhmadSarakhsi.Mabsut.xml'\n",
    "\n",
    "khoja = stemmer_xml2df(stemmed_file)\n",
    "print(khoja.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stemmed_file = '/home/jvdzwaan/data/tmp/adh/stemmer/0483IbnAhmadSarakhsi.Mabsut.xml'\n",
    "\n",
    "khoja = stemmer_xml2df2(stemmed_file)\n",
    "print(khoja.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "khoja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "khoja['farada'] = khoja.apply(lambda row: row['word'] in farada, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "khoja['farada'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root farada\n",
    "root = 'فرض'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "khoja['proposed_root_farada'] = khoja[proposed_root_farada] == root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "khoja['proposed_root_farada'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlap\n",
    "khoja['overlap'] = (khoja['farada'] == True) & (khoja['proposed_root_farada'] == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "khoja['overlap'].sum()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

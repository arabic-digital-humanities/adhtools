{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 16:07:14.751608. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def analyzer_xml2words_and_headers(fname):\n",
    "    words = {}\n",
    "    headers = {}\n",
    "    metadata = b'<metadata></metadata>'\n",
    "    \n",
    "    # Extract the words\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('word'))\n",
    "    for event, elem in tqdm(context):\n",
    "        if elem.tag == 'word':\n",
    "            w_id = elem.attrib['w_id']\n",
    "            # Setting method to html (instead of xml) fixes problems\n",
    "            # with writing Arabic characters in the value attribute of\n",
    "            # the word element.\n",
    "            words[int(w_id)] = etree.tostring(elem, encoding='utf-8', method='html')\n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "            \n",
    "    del context\n",
    "\n",
    "    # Extract the headers\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('header'))\n",
    "    for event, elem in tqdm(context):\n",
    "        level = int(elem.attrib['level'])\n",
    "        if level not in headers:\n",
    "            headers[level] = {}\n",
    "            \n",
    "        header_title = elem.attrib['text']\n",
    "        for ref in elem.getchildren():\n",
    "            if ref.tag == 'ref':\n",
    "                headers[level][int(ref.attrib['id'])] = header_title\n",
    "        #if elem.tag == 'metadata':\n",
    "        #    metadata = etree.tostring(elem, encoding='utf-8')\n",
    "                    \n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    \n",
    "    # Extract the metadata\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('metadata'))\n",
    "    for event, elem in tqdm(context):\n",
    "        metadata = etree.tostring(elem, encoding='utf-8')\n",
    "                    \n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "            \n",
    "    return words, headers, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 16:07:15.984114. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n",
      "17891it [00:01, 16398.25it/s]\n",
      "166it [00:00, 731.46it/s]\n",
      "1it [00:00,  4.61it/s]\n"
     ]
    }
   ],
   "source": [
    "#xml_file = '/home/jvdzwaan/data/tmp/adh/chapters/0381IbnBabawayh.Hidaya.xml'\n",
    "xml_file = '/home/dafne/bridging-the-gap/data/20181009/books/0381IbnBabawayh.Hidaya.xml'\n",
    "words, headers, metadata = analyzer_xml2words_and_headers(xml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17891 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 16:07:18.641954. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    }
   ],
   "source": [
    "print(len(words), len(headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 16:07:21.699321. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 16:07:23.340093. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1345"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many headers?\n",
    "len(headers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 16:07:42.712104. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'باب معرفة الأئمة الذين هم حجج الله على خلقه بعد نبيه صلوات عليه'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers[2][426]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 17:03:04.605440. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    }
   ],
   "source": [
    "headers.get(1, {}).update(headers.get(2, {}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 17:02:48.692656. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
       "If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\n",
       "If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
       "In either case, this is followed by: for k in F:  D[k] = F[k]\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = headers[2]\n",
    "h.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 16:32:51.153683. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'<metadata>\\n<meta name=\"BookSUBJ\">\\xd8\\xb4\\xd9\\x8a\\xd8\\xb9\\xd9\\x8a</meta>\\n<meta name=\"Number_of_tokens\">19733</meta>\\n<meta name=\"AuthorAKA\">\\xd8\\xa5\\xd8\\xa8\\xd9\\x86 \\xd8\\xa8\\xd8\\xa7\\xd8\\xa8\\xd9\\x88\\xd9\\x8a\\xd9\\x87</meta>\\n<meta name=\"AuthorNAME\">\\xd8\\xa7\\xd9\\x84\\xd8\\xb4\\xd9\\x8a\\xd8\\xae \\xd8\\xa7\\xd9\\x84\\xd8\\xa3\\xd9\\x82\\xd8\\xaf\\xd9\\x85 \\xd8\\xa3\\xd8\\xa8\\xd9\\x8a \\xd8\\xac\\xd8\\xb9\\xd9\\x81\\xd8\\xb1 \\xd8\\xa7\\xd9\\x84\\xd8\\xb5\\xd8\\xaf\\xd9\\x88\\xd9\\x82 \\xd9\\x85\\xd8\\xad\\xd9\\x85\\xd8\\xaf \\xd8\\xa8\\xd9\\x86 \\xd8\\xb9\\xd9\\x84\\xd9\\x8a \\xd8\\xa8\\xd9\\x86 \\xd8\\xa7\\xd9\\x84\\xd8\\xad\\xd8\\xb3\\xd9\\x8a\\xd9\\x86 \\xd8\\xa8\\xd9\\x86 \\xd8\\xa8\\xd8\\xa7\\xd8\\xa8\\xd9\\x88\\xd9\\x8a\\xd9\\x87 \\xd8\\xa7\\xd9\\x84\\xd9\\x82\\xd9\\x85\\xd9\\x8a</meta>\\n<meta name=\"AuthorBORNH\">311</meta>\\n<meta name=\"AuthorBORNC\">923</meta>\\n<meta name=\"AuthorDIEDH\">381</meta>\\n<meta name=\"AuthorDIEDC\">992</meta>\\n<meta name=\"Century\">4th/10th century</meta>\\n<meta name=\"All_tokens_per-century\">nan</meta>\\n<meta name=\"BookTITLE\">\\xd8\\xa7\\xd9\\x84\\xd9\\x87\\xd8\\xaf\\xd8\\xa7\\xd9\\x8a\\xd8\\xa9 \\xd9\\x81\\xd9\\x8a \\xd8\\xa7\\xd9\\x84\\xd8\\xa3\\xd8\\xb5\\xd9\\x88\\xd9\\x84 \\xd9\\x88\\xd8\\xa7\\xd9\\x84\\xd9\\x81\\xd8\\xb1\\xd9\\x88\\xd8\\xb9</meta>\\n<meta name=\"Author_Geographical_Area\">Iran</meta>\\n<meta name=\"Tagging\">Chapters ### ||</meta>\\n<meta name=\"BookVOLS\">2</meta>\\n<meta name=\"BookURI\">0381IbnBabawayh.Hidaya</meta>\\n<meta name=\"VolumeTitle\">abc</meta></metadata>\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_elem = etree.fromstring(metadata)\n",
    "lev1_el = etree.Element('meta', attrib={'name': 'VolumeTitle'})\n",
    "lev1_el.text = 'abc'\n",
    "metadata_elem.append(lev1_el)\n",
    "etree.tostring(metadata_elem, encoding='utf-8', pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: add chapter name / number to metadata\n",
    "import os\n",
    "import codecs\n",
    "import shutil\n",
    "\n",
    "from nlppln.utils import out_file_name\n",
    "\n",
    "def write_xml(xml_out, metadata, words, analysis_tag = 'morphology_analysis', lev1_title='', lev2_title=''):\n",
    "    total_words = len(words)\n",
    "    with codecs.open(xml_out, 'wb') as f:\n",
    "        f.write(b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "        f.write(b'<document>\\n')\n",
    "\n",
    "        ## Add metadata\n",
    "        if lev1_title=='':\n",
    "            lev1_title = '-'\n",
    "        if lev2_title=='':\n",
    "            lev2_title = '-'   \n",
    "        metadata_elem = etree.fromstring(metadata)\n",
    "        metadata_elem.append(etree.fromstring('<meta name=\"VolumeTitle\">{}</meta>'.format(lev1_title)))\n",
    "        metadata_elem.append(etree.fromstring('<meta name=\"ChapterTitle\">{}</meta>'.format(lev2_title)))\n",
    "        \n",
    "        f.write(etree.tostring(metadata_elem, encoding='utf-8', pretty_print=True))\n",
    "        f.write(b'\\n')\n",
    "\n",
    "        tag = '<{} total_words=\"{}\">\\n'.format(analysis_tag, total_words)\n",
    "        f.write(tag.encode('utf-8'))\n",
    "\n",
    "        for w in words:\n",
    "            f.write(w)\n",
    "\n",
    "        f.write('</{}>\\n'.format(analysis_tag).encode('utf-8'))\n",
    "\n",
    "        #f.write(markers)\n",
    "\n",
    "        f.write(b'</document>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 17:09:40.530369. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    }
   ],
   "source": [
    "def get_out_file_name(doc_name, out_dir, i):\n",
    "    fname = '{}-{:05}.xml'.format(doc_name, i)\n",
    "    fname = out_file_name(out_dir, fname)\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dafne/anaconda2/envs/adh/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2018-10-09 17:09:58.707595. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available headers: [2]\n"
     ]
    }
   ],
   "source": [
    "#out_dir = '/home/jvdzwaan/data/tmp/adh/chapter-files/'\n",
    "out_dir = '/home/dafne/bridging-the-gap/data/20181009/chapters/'\n",
    "doc_name = os.path.splitext(os.path.basename(xml_file))[0]\n",
    "header_ids = None\n",
    "\n",
    "\n",
    "header_ids = list(headers.get(1, {}).keys()) + list(headers.get(2, {}).keys() )\n",
    "\n",
    "if(len(header_ids)>0):\n",
    "    # do the stuff\n",
    "    print('Available headers: {}'.format(list(headers.keys())))\n",
    "    text = []\n",
    "    header1 = False\n",
    "    header2 = False\n",
    "    i = 0\n",
    "    header1_name = ''\n",
    "    header2_name = ''\n",
    "    for wid, word in words.items():\n",
    "        # Level 1 header\n",
    "        if wid in headers.get(1,{}):\n",
    "            if header1 == False:\n",
    "                if len(text) > 0:\n",
    "                    # start of new header\n",
    "                    # write text to file\n",
    "                    fname = get_out_file_name(doc_name, out_dir, i)\n",
    "                    write_xml(fname, metadata, text, lev1_title=header1_name, lev2_title=header2_name)\n",
    "                    \n",
    "                    #reset\n",
    "                    text = []\n",
    "                    header2_name = headers[1][wid]\n",
    "                    i += 1\n",
    "                header1 = True\n",
    "        else:\n",
    "            header1 = False\n",
    "        \n",
    "        # Level 2 header\n",
    "        if wid in headers.get(2,{}):\n",
    "            if header2 == False:\n",
    "                if len(text) > 0:\n",
    "                    # start of new header\n",
    "                    # write text to file\n",
    "                    fname = get_out_file_name(doc_name, out_dir, i)\n",
    "                    write_xml(fname, metadata, text, lev1_title=header1_name, lev2_title=header2_name)\n",
    "                    \n",
    "                    #reset\n",
    "                    text = []\n",
    "                    header2_name = headers[2][wid]\n",
    "                    i += 1\n",
    "                header2 = True\n",
    "        else:\n",
    "            header2 = False\n",
    "        \n",
    "        text.append(word)\n",
    "else:\n",
    "    # no header information, just copy the input file\n",
    "    print('No headers in', doc_name)\n",
    "    fo = out_file_name(out_dir, xml_file)\n",
    "    if os.path.abspath(xml_file) != fo:\n",
    "        shutil.copy2(xml_file, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Geen headers: gewoon hele file outputten (0182AbuYusufYacqub.Kharaj.xml)\n",
    "* Alleen header 1: file voor elke header (0373AbuLaythSamarqandi.CuyunMasail.xml)\n",
    "* Alleen header 2: file voor elke header (0381IbnBabawayh.Hidaya.xml)\n",
    "  * Er zou text voor de eerste header kunnen staan, wordt die goed meegenomen?\n",
    "* Header 1 en header 2: (0897IbnYusufCabdariGharnati.TajWaIklilLiMukhtasarKhalil.xml)\n",
    "  * Als er tekst is tussen het einde van header 1 en het begin van header 2, moet die in een aparte file worden opgeslagen, anders komt de header 1 tekst bij het volgende chapter\n",
    "  * Als er tekst is voor header 1 begint, aparte file\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adh]",
   "language": "python",
   "name": "conda-env-adh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

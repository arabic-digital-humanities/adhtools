{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "xml_stemmer_results = '/home/jvdzwaan/Downloads/stemmer-output/results_KHOJA_STEMMER.xml'\n",
    "\n",
    "with codecs.open(xml_stemmer_results, encoding='utf-8') as f:\n",
    "    soup = BeautifulSoup(f, 'lxml')\n",
    "words = soup.find_all('word')\n",
    "\n",
    "for w in words:\n",
    "    print w['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frog csv (or tsv) should have fields:\n",
    "#\n",
    "#    Token number (resets every sentence)\n",
    "#    Token\n",
    "#    Lemma (according to MBLEM)\n",
    "#    Morphological segmentation (according to MBMA)\n",
    "#    PoS tag (CGN tagset; according to MBT)\n",
    "#    Confidence in the POS tag, a number between 0 and 1, representing the probability mass assigned to the best guess tag in the tag distribution\n",
    "#    Named entity type, identifying person (PER), organization (ORG), location (LOC), product (PRO), event (EVE), and miscellaneous (MISC), using a BIO (or IOB2) encoding\n",
    "#    Base (non-embedded) phrase chunk in BIO encoding\n",
    "#    Token number of head word in dependency graph (according to CSI-DP)\n",
    "#    Type of dependency relation with head word\n",
    "\n",
    "result = []\n",
    "for i, w in enumerate(words):\n",
    "    stem = w.find('analysis')['stem']\n",
    "    result.append({'token_number': i,\n",
    "                   'token': w['value'],\n",
    "                   'lemma': stem,\n",
    "                   'morphological_segmentation': '[bla]',\n",
    "                   'pos_tag': 'SPEC(deeleigen)',\n",
    "                   'pos_confidence': 0.05,\n",
    "                   'ne_type': 'O',\n",
    "                   'base': 'O',\n",
    "                   'token_nr_head_word': 0,\n",
    "                   'dep_type': 'ROOT'})\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to tsv without heading row\n",
    "# format is tsv-folia\n",
    "#    Token number (resets every sentence)\n",
    "#    Token\n",
    "#    Lemma (according to MBLEM)\n",
    "#    Morphological segmentation (according to MBMA)\n",
    "#    PoS tag (CGN tagset; according to MBT)\n",
    "#    Confidence in the POS tag, a number between 0 and 1, representing the probability mass assigned to the best guess tag in the tag distribution\n",
    "#    Named entity type, identifying person (PER), organization (ORG), location (LOC), product (PRO), event (EVE), and miscellaneous (MISC), using a BIO (or IOB2) encoding\n",
    "#    Base (non-embedded) phrase chunk in BIO encoding\n",
    "#    Token number of head word in dependency graph (according to CSI-DP)\n",
    "#    Type of dependency relation with head word\n",
    "cols = [u'token_number', u'token', u'lemma', u'morphological_segmentation', u'pos_tag',\n",
    "        u'pos_confidence', u'ne_type', u'base', u'token_nr_head_word', u'dep_type']\n",
    "df.to_csv('/home/jvdzwaan/data/tmp/fake-arabic-folia.tsv', columns=cols, sep='\\t', header=False, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simpler tsv format\n",
    "# apparently requires header\n",
    "df2 = df[[u'token', u'lemma', u'pos_tag']]\n",
    "df2.columns = ['word', 'lemma', 'pos']\n",
    "df2.to_csv('/home/jvdzwaan/data/tmp/fake-arabic/fake-arabic.tsv', sep='\\t', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

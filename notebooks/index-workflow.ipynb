{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow for single book\n",
    "from nlppln import WorkflowGenerator\n",
    "#cwl_working_dir = '/home/dafne/cwl-working-dir/'\n",
    "cwl_working_dir = '/home/jvdzwaan/cwl-working-dir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with WorkflowGenerator(working_dir=cwl_working_dir) as wf_sub:\n",
    "    wf_sub.load(steps_dir='../adhtools/cwl/')\n",
    "    wf_sub.load(steps_dir='../java/cwl/')\n",
    "    print(wf_sub.list_steps())\n",
    "    \n",
    "    analyzer = wf_sub.add_input(analyzer='string', default='Alkhalil')\n",
    "    book = wf_sub.add_input(book='File')\n",
    "    cp = wf_sub.add_input(cp='string')\n",
    "    \n",
    "    metadata, txt_dir = wf_sub.txt2safar_input(in_file=book)\n",
    "    analyzed_files = wf_sub.SafarAnalyze(in_dir=txt_dir, analyzer=analyzer, cp=cp)\n",
    "    safar_output_dir = wf_sub.safar_add_metadata(in_files=analyzed_files, meta_in=metadata)\n",
    "    \n",
    "    wf_sub.add_outputs(safar_output_dir=safar_output_dir)\n",
    "    \n",
    "    wf_sub.save('../adhtools/cwl/safar-workflow.cwl', wd=True, relative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with WorkflowGenerator(working_dir=cwl_working_dir) as wf:\n",
    "    wf.load(steps_dir='../adhtools/cwl/')\n",
    "    wf.load(steps_dir='../java/cwl/')\n",
    "    wf.load(step_file='https://raw.githubusercontent.com/arabic-digital-humanities/BlackLabIndexer-docker/master/blacklabindexer.cwl')\n",
    "    \n",
    "    print(wf.list_steps())\n",
    "    \n",
    "    analyzer = wf.add_input(analyzer='string', default='Alkhalil')\n",
    "    book = wf.add_input(book='File')\n",
    "    cp = wf.add_input(cp='string')\n",
    "    index_name = wf.add_input(index_name='string', default='corpus')\n",
    "    action = wf.add_input(action='string', default='create')\n",
    "    index_format = wf.add_input(index_format='string', default='safar-analyzer')\n",
    "    text_direction = wf.add_input(text_direction='string', default='rtl')\n",
    "    content_viewable = wf.add_input(content_viewable='boolean', default=True)\n",
    "    \n",
    "    safar_output_dir = wf.safar_workflow(analyzer=analyzer, book=book, cp=cp) #, scatter='book'\n",
    "    indexed = wf.blacklabindexer(action=action, \n",
    "                                 index_format=index_format, \n",
    "                                 index_name=index_name, \n",
    "                                 in_dir=safar_output_dir, \n",
    "                                 text_direction=text_direction, \n",
    "                                 content_viewable=content_viewable)\n",
    "    \n",
    "    wf.add_outputs(indexed=indexed)\n",
    "    \n",
    "    wf.add_outputs(safar_output_dir=safar_output_dir)\n",
    "    \n",
    "    wf.save('../adhtools/cwl/process.cwl', wd=True, relative=False)\n",
    "    \n",
    "    # select txt files -> ls?\n",
    "    # divide and extract metadata -> safar2text_and_metadata\n",
    "    # save to dir -> save_to_dir\n",
    "    # safar analyze -> SafarAnalyze.java -> maak dat ie uit dir leest\n",
    "    # add metadata -> safar_add_metadata\n",
    "    # index with blacklab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the scattered version\n",
    "with WorkflowGenerator(working_dir=cwl_working_dir) as wf:\n",
    "    wf.load(steps_dir='../adhtools/cwl/')\n",
    "    wf.load(steps_dir='../java/cwl/')\n",
    "    wf.load(step_file='https://raw.githubusercontent.com/arabic-digital-humanities/BlackLabIndexer-docker/master/blacklabindexer.cwl')\n",
    "    \n",
    "    print(wf.list_steps())\n",
    "    \n",
    "    analyzer = wf.add_input(analyzer='string', default='Alkhalil')\n",
    "    in_dir = wf.add_input(in_dir='Directory')\n",
    "    cp = wf.add_input(cp='string')\n",
    "    index_name = wf.add_input(index_name='string', default='corpus')\n",
    "    action = wf.add_input(action='string', default='create')\n",
    "    index_format = wf.add_input(index_format='string', default='safar-analyzer')\n",
    "    text_direction = wf.add_input(text_direction='string', default='rtl')\n",
    "    content_viewable = wf.add_input(content_viewable='boolean', default=True)\n",
    "    \n",
    "    books = wf.ls(in_dir=in_dir)\n",
    "    safar_output_dirs = wf.safar_workflow(analyzer=analyzer, book=books, cp=cp, scatter='book', scatter_method='dotproduct')\n",
    "    merged_dir = wf.gather_dirs(in_dirs=safar_output_dirs)\n",
    "    indexed = wf.blacklabindexer(action=action, \n",
    "                                 index_format=index_format, \n",
    "                                 index_name=index_name, \n",
    "                                 in_dir=merged_dir, \n",
    "                                 text_direction=text_direction, \n",
    "                                 content_viewable=content_viewable)\n",
    "    wf.add_outputs(indexed=indexed)\n",
    "    \n",
    "    wf.add_outputs(safar_output_dirs=safar_output_dirs)\n",
    "    wf.add_outputs(merged_dir=merged_dir)\n",
    "    \n",
    "    wf.save('../adhtools/cwl/process_dir.cwl', wd=True, relative=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

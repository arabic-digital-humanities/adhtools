{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlppln.utils import get_files, create_dirs, out_file_name\n",
    "\n",
    "gs_dir = '/home/jvdzwaan/data/tmp/adh/evaluation/gs/'\n",
    "gs_files = get_files(gs_dir)\n",
    "\n",
    "gs = pd.concat([pd.read_csv(f) for f in gs_files])\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_roots = [root.split('\\\\') for root in list(gs['root'])]\n",
    "print(gs_roots[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "gs_root_counts = Counter()\n",
    "\n",
    "for rs in gs_roots:\n",
    "    for r in rs:\n",
    "        gs_root_counts[r] += 1\n",
    "        \n",
    "print(len(gs_root_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from nlppln.utils import get_files, create_dirs, out_file_name\n",
    "\n",
    "from adhtools.utils import corpus_wordlist\n",
    "\n",
    "def pickle_roots(in_dir, out_dir, analyzer):\n",
    "\n",
    "    in_files = get_files(in_dir)\n",
    "\n",
    "    create_dirs(out_dir)\n",
    "\n",
    "    for roots_in_file, in_file in tqdm(zip(corpus_wordlist(in_files, analyzer=analyzer), \n",
    "                                           in_files), total=len(in_files)):\n",
    "        res = [set(root.split('\\\\')) for root in roots_in_file]\n",
    "        #print(len(res))\n",
    "        #print(res[0])\n",
    "        out_file = out_file_name(out_dir, in_file, ext='pkl')\n",
    "        #print(out_file)\n",
    "        with open(out_file, 'wb') as f:\n",
    "            pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khoja\n",
    "khoja_in_dir = '/home/jvdzwaan/data/tmp/adh/20190325-fiqh-khoja/'\n",
    "analyzer= False\n",
    "\n",
    "khoja_out_dir = '/home/jvdzwaan/data/tmp/adh/20190325-fiqh-khoja-roots/'\n",
    "\n",
    "#pickle_roots(khoja_in_dir, khoja_out_dir, analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISRI\n",
    "isri_in_dir = '/home/jvdzwaan/data/tmp/adh/20190326-fiqh-isri/'\n",
    "analyzer= False\n",
    "\n",
    "isri_out_dir = '/home/jvdzwaan/data/tmp/adh/20190326-fiqh-isri-roots/'\n",
    "\n",
    "#pickle_roots(isri_in_dir, isri_out_dir, analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlKhalil\n",
    "alk_in_dir = '/home/jvdzwaan/Downloads/2019-02-08-fiqh-newfiles-alkhalil/'\n",
    "analyzer= True\n",
    "\n",
    "alk_out_dir = '/home/jvdzwaan/data/tmp/adh/2019-02-08-fiqh-newfiles-alkhalil-roots/'\n",
    "\n",
    "#pickle_roots(alk_in_dir, alk_out_dir, analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result: df met counts voor elke root in gs en index is files\n",
    "import os\n",
    "\n",
    "def count_gs_roots(pkl_dir, gs_root_counts):\n",
    "\n",
    "    res = {}\n",
    "\n",
    "    in_files = get_files(pkl_dir)\n",
    "    for in_file in tqdm(in_files):\n",
    "        file_root_counts = Counter()\n",
    "        with open(in_file, 'rb') as f:\n",
    "            roots = pickle.load(f)\n",
    "        for rs in roots:\n",
    "            for r in rs:\n",
    "                if r in gs_root_counts.keys():\n",
    "                    file_root_counts[r] += 1\n",
    "\n",
    "        file_root_counts['total'] = len(roots)\n",
    "        book_id = os.path.splitext(str(os.path.basename(in_file)))[0]\n",
    "        res[book_id] = file_root_counts\n",
    "        #break\n",
    "    tool_df = pd.DataFrame.from_dict(res, orient='index')\n",
    "    \n",
    "    tool_df = tool_df.fillna(0)\n",
    "\n",
    "    roots_not_found = []\n",
    "\n",
    "    for r in gs_root_counts.keys():\n",
    "        if r not in tool_df.columns:\n",
    "            tool_df[r] = 0\n",
    "            roots_not_found.append(r)\n",
    "    return tool_df, roots_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "khoja_df, khoja_roots_not_found = count_gs_roots(khoja_out_dir, gs_root_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isri_df, isri_roots_not_found = count_gs_roots(isri_out_dir, gs_root_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alk_df, alk_roots_not_found = count_gs_roots(alk_out_dir, gs_root_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine with metadata\n",
    "# set schools (Shii Sunni)\n",
    "# group by school\n",
    "# calculate percentages for each column\n",
    "# plot: for a given root, the percentages per school for each tool\n",
    "\n",
    "def set_schools(row):\n",
    "    if row['BookSUBJ'] == 'جعفري':\n",
    "        return 'Shi\\''\n",
    "    return 'Sunn'\n",
    "\n",
    "def combine_with_metadata(md_file, df):\n",
    "    md = pd.read_csv(md_file, sep=';|,')\n",
    "    md = md.set_index('BookURI')\n",
    "    \n",
    "    result = pd.concat([df.copy(), md.copy()], axis=1, sort=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_percentages(df):\n",
    "    cols = []\n",
    "    for c in df.columns:\n",
    "        print(c)\n",
    "        c_total = df.loc['total', c]\n",
    "        print(c_total)\n",
    "        n = '{}i'.format(c)\n",
    "        cols.append(n)\n",
    "        df[n] = df[c]/c_total *100.0\n",
    "    \n",
    "    return df, cols\n",
    "\n",
    "def preprocess(df, md_file):\n",
    "    data = combine_with_metadata(md_file, df)\n",
    "    data['school'] = data.apply(lambda row: set_schools(row), axis=1)\n",
    "    data = data.groupby('school').sum().T\n",
    "    return calculate_percentages(data)\n",
    "\n",
    "md_file = '/home/jvdzwaan/data/adh-corpora/fiqh_corpus/Meta/Metadata_Fiqh.csv'\n",
    "\n",
    "khoja, k_cols = preprocess(khoja_df, md_file)\n",
    "isri, i_cols = preprocess(isri_df, md_file)\n",
    "alkhalil, a_cols = preprocess(alk_df, md_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords as sw\n",
    "\n",
    "def get_terms(txt_file):\n",
    "    # get the terms list\n",
    "    terms = pd.read_csv(txt_file, encoding='utf-8', index_col=None, header=None)\n",
    "    t = terms[0].tolist()\n",
    "    print('total number of terms:', len(t))\n",
    "    terms = set(t)\n",
    "    print('number of unique terms:', len(terms))\n",
    "    return terms\n",
    "\n",
    "stopwords = get_terms('/home/jvdzwaan/data/adh/stopwords/custom.txt')\n",
    "\n",
    "stopwords_nltk = list(sw.words('arabic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_root_tools(khoja, isri, alkhalil, root, cols, sw_n, sw_c, gs_root_counts):\n",
    "    sw = sw_type(root, sw_n, sw_c)\n",
    "\n",
    "    #print(root, sw, 'freq. in gs:', gs_root_counts[root])\n",
    "    #print(cols)\n",
    "    to_plot = pd.DataFrame()\n",
    "    #print(khoja.loc[root])\n",
    "    to_plot['khoja'] = khoja.loc[root]\n",
    "    to_plot['isri'] = isri.loc[root]\n",
    "    to_plot['alkhalil'] = alkhalil.loc[root]\n",
    "    \n",
    "    #print(to_plot.loc[cols].T)\n",
    "    #print(np.allclose(to_plot.loc[cols[0]]))\n",
    "    #print(np.allclose(to_plot.loc[cols[1]]))\n",
    "    \n",
    "    return to_plot.loc[cols].T\n",
    "\n",
    "\n",
    "def sw_type(root, sw_n, sw_c):\n",
    "    #print(len(sw_n), len(sw_c))\n",
    "    n = root in sw_n\n",
    "    c = root in sw_c\n",
    "    \n",
    "    if n and c:\n",
    "        return '(b)'\n",
    "    elif n:\n",
    "        return '(n)'\n",
    "    elif c:\n",
    "        return '(c)'\n",
    "    return '(not a stopword)'\n",
    "\n",
    "\n",
    "\n",
    "plot_root_tools(khoja, isri, alkhalil, khoja.index[116], k_cols, stopwords_nltk, stopwords, gs_root_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = alkhalil.copy()\n",
    "k.columns = ['Shi', 'Sunn', 'Shi\\'i', 'Sunni']\n",
    "k.query(\"Shii == 0 and Sunni == 0\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "num_with_zero = 0\n",
    "num_with_zero_sw = 0\n",
    "num_sw = 0\n",
    "\n",
    "non_zero = []\n",
    "\n",
    "for root in gs_root_counts.keys():\n",
    "    res = plot_root_tools(khoja, isri, alkhalil, root, k_cols, stopwords_nltk, stopwords, gs_root_counts)\n",
    "    \n",
    "    #print(res)\n",
    "    \n",
    "    sw = False\n",
    "    if root in stopwords_nltk or root in stopwords:\n",
    "        sw = True\n",
    "        num_sw += 1\n",
    "    else:\n",
    "        print(root, sw, 'freq. in gs:', gs_root_counts[root])\n",
    "        print(res)\n",
    "        res.plot(kind='bar', figsize=(7,5), fontsize=12)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.show() \n",
    "    \n",
    "    nz_tools = res.apply(lambda row: np.count_nonzero(row), axis=1)\n",
    "    #print(nz_tools)\n",
    "    non_zero.append(nz_tools)\n",
    "    nz = np.count_nonzero(nz_tools)\n",
    "    if nz != 3:\n",
    "        num_with_zero += 1\n",
    "        if sw:\n",
    "            num_with_zero_sw += 1\n",
    "\n",
    "    \n",
    "    #c = res[k_cols[0]] > res[k_cols[1]]\n",
    "    #if c.sum() != 0 and c.sum() != 3:\n",
    "    #    print('Differences for', root)\n",
    "    #    print(res)\n",
    "    #    res.plot(kind='bar')\n",
    "    #    plt.show() \n",
    "    #    num += 1\n",
    "print('khoja non zero', np.sum(pd.DataFrame(non_zero)['khoja'] == 0))\n",
    "print('isri non zero', np.sum(pd.DataFrame(non_zero)['isri'] == 0))\n",
    "print('alkhalil non zero', np.sum(pd.DataFrame(non_zero)['alkhalil'] == 0))\n",
    "print('num stopwords', num_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_with_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_with_zero_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_roots = set(gs_root_counts.keys())\n",
    "print(len(gs_roots))\n",
    "pred_roots = set(khoja.index)\n",
    "\n",
    "print(pred_roots.difference(gs_roots))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

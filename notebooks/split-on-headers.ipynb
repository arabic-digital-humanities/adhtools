{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "import codecs\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from Bio import pairwise2\n",
    "\n",
    "from nlppln.utils import create_dirs, out_file_name\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # nltk tokenizer replaces \" (double quotes) with `` and ''.\n",
    "    # We want to keep the double quotes, so replace them again.\n",
    "    tokens = ['\"' if t == '``' or t == \"''\" else t for t in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def get_spaces_pattern(text):\n",
    "    # replace regular expressions special characters\n",
    "    for p in ('(', ')'):\n",
    "            text = text.replace(p, '#')\n",
    "    tokens = tokenize(text)\n",
    "    m = re.match(r'( *)'.join(tokens), text)\n",
    "    return m.groups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = '/home/jvdzwaan/data/tmp/adh/merge-test/text.txt'\n",
    "text_file = '/home/jvdzwaan/data/tmp/adh/merge-test/0179MalikIbnAnas.Muwatta.txt'\n",
    "text_file = '/home/jvdzwaan/data/adh-corpora/fiqh_corpus/txt/0381IbnBabawayh.Hidaya.txt'\n",
    "text_file = '/home/jvdzwaan/data/adh-corpora/fiqh_corpus/txt/1078ShaykhiZadahDamadAfandi.MajmacAnhur..txt'\n",
    "text_file = '/home/jvdzwaan/data/adh-corpora/fiqh_corpus/txt/1122MuhammadZarqani.SharhCalaMuwatta.txt'\n",
    "with open(text_file) as f:\n",
    "    text = f.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(re.finditer('\\u2028', text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "from nlppln.utils import get_files\n",
    "\n",
    "for txt_file in get_files('/home/jvdzwaan/data/adh-corpora/fiqh_corpus/txt/'):\n",
    "#for txt_file in get_files('/home/jvdzwaan/data/adh-corpora/dawa/'):\n",
    "#for txt_file in get_files('/home/jvdzwaan/data/adh-corpora/poetry/txt/'):\n",
    "    with open(txt_file) as f:\n",
    "        text = f.read()\n",
    "    matches = re.findall('\\u2028', text)\n",
    "    if len(matches) > 0:\n",
    "        print(os.path.basename(txt_file), len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_file = '/home/jvdzwaan/data/tmp/adh/merge-test/text.txt'\n",
    "#text_file = '/home/jvdzwaan/data/tmp/adh/merge-test/0179MalikIbnAnas.Muwatta.txt'\n",
    "#text_file = '/home/jvdzwaan/data/adh-corpora/fiqh_corpus/txt/0381IbnBabawayh.Hidaya.txt'\n",
    "text_file = '/home/jvdzwaan/data/adh-corpora/fiqh_corpus/txt/1078ShaykhiZadahDamadAfandi.MajmacAnhur..txt'\n",
    "#text_file = '/home/jvdzwaan/data/adh-corpora/fiqh_corpus/txt/1122MuhammadZarqani.SharhCalaMuwatta.txt'\n",
    "with open(text_file) as f:\n",
    "    text = f.read()\n",
    "print(text)\n",
    "\n",
    "text = text.replace('\\u2028', '\\n')\n",
    "print(text)\n",
    "\n",
    "with open(text_file, 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = r'\\| \\#{1,}(.+)\\n'\n",
    "#print(regex)\n",
    "match = re.search(regex, text)\n",
    "header = match.group(1).strip()\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(text)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def analyzer_xml2df(fname):\n",
    "    #print(fname)\n",
    "    with codecs.open(fname) as f:\n",
    "        soup = BeautifulSoup(f.read(), 'xml')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for word in soup.find_all('word'):\n",
    "        analyses = word.find_all('analysis')\n",
    "        roots = [a.get('root', 'NO_ROOT') for a in analyses]\n",
    "        roots = list(set(roots))\n",
    "        if len(roots) == 0:\n",
    "            roots.append('NOANALYSIS')\n",
    "        result.append({'word': word['value'], 'proposed_root': '\\\\'.join(roots), 'id': word['w_id']})\n",
    "    \n",
    "    #print(len(result))\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = '/home/jvdzwaan/data/tmp/adh/merge-test/text.xml'\n",
    "xml_file = '/home/jvdzwaan/data/tmp/adh/merge-test/0179MalikIbnAnas.Muwatta.xml'\n",
    "\n",
    "df = analyzer_xml2df(xml_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = pairwise2.align.localms(tokens,list(df['word']),2,-1,-0.5,-0.1, gap_char=[\"GAP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_tok = tokenize(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = False\n",
    "level = 0\n",
    "header_words = []\n",
    "w_ids = []\n",
    "w_id = 0\n",
    "\n",
    "for t1, t2 in zip(alignment[0][0], alignment[0][1]):\n",
    "    if t2 != 'GAP':\n",
    "        w_id += 1\n",
    "\n",
    "    if t1 == '|':\n",
    "        h = True\n",
    "    elif h and t1 == '#':\n",
    "        level += 1\n",
    "    elif t1 == 'NEWLINE': # end of header\n",
    "        if h:\n",
    "            print('HEADER [{}] {} ({})'.format(level, ' '.join(header_words), ', '.join(w_ids)))\n",
    "        h = False\n",
    "        level = 0\n",
    "        header_words = []\n",
    "        w_ids = []\n",
    "    elif h and t2 != 'GAP':\n",
    "        header_words.append(t2)\n",
    "        w_ids.append(str(w_id))\n",
    "        #print('H', t1)\n",
    "    #print(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t1, t2 in zip(alignment[0][0], alignment[0][1]):\n",
    "    print(t1,t2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'\\| \\#\\#\\#(.+?)\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openiti headers\n",
    "regex = r'\\#\\#\\# (?P<level>\\|+) (?P<text>.+?)\\n'\n",
    "for m in re.finditer(regex, text):\n",
    "    print(m)\n",
    "    print(len(m.group(1)))\n",
    "    print(m.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'level' in m.groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quran/hadith quotes\n",
    "regex = r'@(?P<source>[QH])B@(?P<text>.+?)@(?P=source)E@'\n",
    "for m in re.finditer(regex, text):\n",
    "    print(m)\n",
    "    print(m.group('source'))\n",
    "    print(m.group('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openiti headers and quran/hadith quotes\n",
    "regex = r'\\#\\#\\# (?P<level>\\|+) (?P<header>.+?)\\n|@(?P<source>[QH])B@(?P<quote>.+?)@(?P=source)E@'\n",
    "for m in re.finditer(regex, text):\n",
    "    print(m)\n",
    "    print(m.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "\n",
    "for m in re.finditer(regex, text):\n",
    "    print(m)\n",
    "    prev_text = text[start:m.start()]\n",
    "    print(len(prev_text.strip()))\n",
    "    print(repr(prev_text))\n",
    "    import sys\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "print(unicodedata.category('\\u200f'))\n",
    "print(unicodedata.category('пе'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_strip(text, to_remove=('\\u200f')):\n",
    "    text = ''.join(list(filter(lambda char: char not in to_remove, text)))\n",
    "    return text.strip()\n",
    "\n",
    "print(repr(smart_strip('\\n\\n\\n\\n\\n\\n\\n\\u200f')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'\\#\\#\\# (\\||\\|\\|) (.+?)\\n'\n",
    "start = 0\n",
    "i = 0\n",
    "names = []\n",
    "\n",
    "out_dir = '/home/jvdzwaan/data/tmp'\n",
    "doc_name = os.path.splitext(os.path.basename(text_file))[0]\n",
    "print(doc_name)\n",
    "for m in re.finditer(regex, text):\n",
    "    print(m)\n",
    "    prev_text = text[start:m.start()]\n",
    "    print(len(smart_strip(prev_text)))\n",
    "    \n",
    "    prev_text = smart_strip(prev_text)\n",
    "    if len(prev_text) > 0:\n",
    "        print('Write file for prev text')\n",
    "        #print(start,m.start())\n",
    "        #print(i)\n",
    "        fname = '{}-{:05}.txt'.format(doc_name, i)\n",
    "        fname = os.path.join(out_dir, fname)\n",
    "        print(fname)\n",
    "        names.append(fname)\n",
    "        i += 1\n",
    "    \n",
    "    print('level {}'.format(len(m.group(1))))\n",
    "    print('header: {}'.format(m.group(2)))\n",
    "    print('Write file for header')\n",
    "    level = len(m.group(1))\n",
    "    fname = '{}-{:05}-header-{}.txt'.format(doc_name, i, level)\n",
    "    fname = os.path.join(out_dir, fname)\n",
    "    print(fname)\n",
    "    names.append(fname)\n",
    "    i += 1\n",
    "    \n",
    "    start = m.end()\n",
    "    \n",
    "    #import sys\n",
    "    #sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.sort()\n",
    "for n in names:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = u\"\\u200f\"\n",
    "print(repr(u\"\\u200f\"))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(c))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

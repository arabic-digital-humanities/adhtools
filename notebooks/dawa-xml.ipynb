{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from lxml import etree\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def read_book(fname, book_id):\n",
    "    result = OrderedDict()\n",
    "    regex = '__________\\n'\n",
    "    \n",
    "    # Extract the words\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('book'))\n",
    "    for event, elem in context:\n",
    "        for e in elem.iterchildren():\n",
    "            if e.tag == 'id':\n",
    "                t_id = e.text\n",
    "                #print(t_id)\n",
    "            elif e.tag == 'nass':   # text\n",
    "                # sometimes the text is None (e.g., file 16, id 214)\n",
    "                text = e.text\n",
    "                fn = None\n",
    "                if text is None:\n",
    "                    print('None text found in {} (prev? id: {})'.format(fname, t_id))\n",
    "                else:\n",
    "                    # &#xd; is automatically replaced by \\r, but we would like to have \\n\n",
    "                    text = text.replace('\\r', '\\n')\n",
    "                    \n",
    "                    # get the footnotes if they are there\n",
    "                    parts = re.split(regex, text)\n",
    "                    \n",
    "                    # we shouln't have parts longer than 2\n",
    "                    if len(parts) > 2:                        \n",
    "                        # all exceptions\n",
    "                        print('book_id', book_id)\n",
    "                        if book_id in (27, 38):\n",
    "                            text = parts[0]\n",
    "                            fn = regex.join(parts[1:])\n",
    "                        elif book_id in (36, 70, 89, 124, 140, 142, 143, 146, 147, 148):\n",
    "                            # seems to be a table of contents and/or index\n",
    "                            # so, put the \n",
    "                            text = ' '\n",
    "                            fn = text\n",
    "                        else:\n",
    "                            pass\n",
    "                            print('More parts found in {} ({})'.format(t_id, len(parts)))\n",
    "                            #print(text)\n",
    "                            #print('---')\n",
    "    \n",
    "                    if len(parts) == 2:\n",
    "                        t, fn = parts\n",
    "                        text = t\n",
    "\n",
    "            elif e.tag == 'page':\n",
    "                page = e.text\n",
    "            elif e.tag == 'part':\n",
    "                part = e.text\n",
    "            #print(e.tag)\n",
    "        \n",
    "        # ignore entries that don't have text\n",
    "        if not text is None:\n",
    "            result[t_id] = {'text': text, 'page': page, 'part': part}\n",
    "        \n",
    "        if not fn is None:\n",
    "            result[t_id]['footnotes'] = fn\n",
    "\n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "book = read_book('/home/jvdzwaan/data/adh-corpora/dawa/New_xml_corpus/1/book.xml', 1)\n",
    "print(len(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_title(fname):\n",
    "    result = {}\n",
    "    levels = {}\n",
    "    \n",
    "    # Extract the words\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('title'))\n",
    "    for event, elem in context:\n",
    "        for e in elem.iterchildren():\n",
    "            if e.tag == 'id':\n",
    "                t_id = e.text\n",
    "                #print(t_id)\n",
    "            elif e.tag == 'tit':\n",
    "                title = e.text\n",
    "                # &#xd; is automatically replaced by \\r, but we would like to have \\n\n",
    "                title = title.replace('\\r', '\\n')\n",
    "            elif e.tag == 'lvl':\n",
    "                level = e.text\n",
    "                levels[level] = None\n",
    "            #print(e.tag)\n",
    "        if not t_id in result.keys():\n",
    "            result[t_id] = []\n",
    "            \n",
    "        result[t_id].append({'title': title, 'level': level})\n",
    "\n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    \n",
    "    #print('levels found:', levels.keys())\n",
    "    return result, levels.keys()\n",
    "\n",
    "title, levels = read_title('/home/jvdzwaan/data/adh-corpora/dawa/New_xml_corpus/1/title.xml')\n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine book and title\n",
    "# and write to file\n",
    "import codecs\n",
    "\n",
    "def combine_data(book, title, out_file):\n",
    "    with codecs.open(out_file, 'w', encoding='utf-8') as f:\n",
    "        for b_id, data in book.items():\n",
    "            text = data['text']\n",
    "            if b_id in title:\n",
    "                #print(b_id)\n",
    "                #print('title!')\n",
    "                #print(title[b_id])\n",
    "                # Sometimes the titles in the xml are in the wrong order\n",
    "                # So sort them to put them in the right order\n",
    "                title[b_id].sort(key=lambda t: int(t['level']))\n",
    "                #print(title[b_id])\n",
    "                #print('---')\n",
    "                for t in title[b_id]:\n",
    "                    ti = t['title']\n",
    "                    lvl = t['level']\n",
    "                    #print(title[b_id]['title'], title[b_id]['level'])\n",
    "                    f.write('### {} {}\\n'.format(int(lvl)*'|', ti))\n",
    "                    #if text.strip().startswith(ti):\n",
    "                    #    print('title in text', b_id)\n",
    "                    #    text = text.replace(ti, '### {} {}\\n'.format(int(lvl)*'|', ti))\n",
    "                    #else:\n",
    "                    #    text = '### {} {}\\n'.format(int(lvl)*'|', ti) + text\n",
    "                    #    print('title text not found', b_id)\n",
    "                    \n",
    "                    # Remove the first occurence of the title string\n",
    "                    text = text.replace(ti, '', 1)\n",
    "            f.write(text.strip())\n",
    "            f.write('\\n')\n",
    "            # sometimes the page marker information is incomplete (e.g. for book 12)\n",
    "            # in that case, we don't write the marker information\n",
    "            if not data['part'] is None and not data['page'] is None:\n",
    "                page = data['page'].split()[0]\n",
    "                part = data['part'].split()[0]\n",
    "                \n",
    "                try:\n",
    "                    part = int(part)\n",
    "                except ValueError:\n",
    "                    print('Invalid part {} ({})'.format(part, out_name))\n",
    "                    part = 0\n",
    "                    \n",
    "                try:\n",
    "                    page = int(page)\n",
    "                except ValueError:\n",
    "                    print('Invalid page {} ({})'.format(page, out_name))\n",
    "                    page = 0\n",
    "                \n",
    "                page_marker = 'V{:03}P{:04}'.format(part, page)\n",
    "                f.write(page_marker)\n",
    "                f.write('\\n')\n",
    "            #print('---')\n",
    "combine_data(book, title, 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "in_dir = '/home/jvdzwaan/data/adh-corpora/dawa/New_xml_corpus/'\n",
    "out_dir = '/home/jvdzwaan/data/adh-corpora/dawa/txt/'\n",
    "notes_dir = '/home/jvdzwaan/data/adh/dawa-notes/'\n",
    "\n",
    "level_data = []\n",
    "\n",
    "for i in tqdm(range(1, 217)):\n",
    "    out_name = '{}.txt'.format(i)\n",
    "    \n",
    "    d = os.path.join(in_dir, str(i))\n",
    "    book_file = os.path.join(d, 'book.xml')\n",
    "    title_file = os.path.join(d, 'title.xml')\n",
    "    #print(book_file)\n",
    "    #print(title_file)\n",
    "    book = read_book(book_file, i)\n",
    "    title, levels = read_title(title_file)\n",
    "    \n",
    "    level_data.append({'book': i, 'levels': list(levels)})\n",
    "    \n",
    "    # write txt to output file\n",
    "    out_file = os.path.join(out_dir, out_name)\n",
    "    print(out_file)\n",
    "    #combine_data(book, title, out_file)\n",
    "    \n",
    "    # write notes, etc. to output file\n",
    "    notes = []\n",
    "    for b_id, data in book.items():\n",
    "        fn = data.get('footnotes')\n",
    "        if fn is not None:\n",
    "            notes.append(fn)\n",
    "    \n",
    "    # save notes to file\n",
    "    if len(notes) > 0:\n",
    "        out_file = os.path.join(notes_dir, out_name)\n",
    "        print('Writing notes to', out_file)\n",
    "        with open(out_file, 'w') as f:\n",
    "            f.write('\\n'.join(notes))\n",
    "            f.write('\\n')\n",
    "                \n",
    "    print('-'*80)\n",
    "    \n",
    "levels = pd.DataFrame(level_data)\n",
    "levels = levels.set_index('book')\n",
    "levels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels.to_csv('dawa_levels.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from lxml import etree\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def read_almanar(fname, book_id=286):\n",
    "    result = OrderedDict()\n",
    "    regex = '__________\\n'\n",
    "    \n",
    "    # Extract the words\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('book'))\n",
    "    for event, elem in context:\n",
    "        for e in elem.iterchildren():\n",
    "            if e.tag == 'id':\n",
    "                t_id = e.text\n",
    "                #print(t_id)\n",
    "            elif e.tag == 'nass':   # text\n",
    "                # sometimes the text is None (e.g., file 16, id 214)\n",
    "                text = e.text\n",
    "                fn = None\n",
    "                if text is None:\n",
    "                    print('None text found in {} (prev? id: {})'.format(fname, t_id))\n",
    "                else:\n",
    "                    # &#xd; is automatically replaced by \\r, but we would like to have \\n\n",
    "                    text = text.replace('\\r', '\\n')\n",
    "                    \n",
    "                    # get the author name and footnotes\n",
    "                    parts = re.split(regex, text)\n",
    "                    \n",
    "                    #print(t_id, len(parts))\n",
    "                    one = parts[0].startswith('الكاتب')\n",
    "                    two = 'الكاتب' in parts[0]\n",
    "                    \n",
    "                    # the author name is always the first word in the part before the line\n",
    "                    if not one and two:\n",
    "                        print('Unexpected in', t_id)\n",
    "                        \n",
    "                    # if there are three parts, the first is always the author name\n",
    "                    # (we assume part[1] is text and part[2] are footnotes)\n",
    "                    if len(parts) == 3: \n",
    "                        if not one:\n",
    "                            print('3 parts found without author name', t_id)\n",
    "                        text = ''.join((parts[0], parts[1]))\n",
    "                        fn = parts[2]\n",
    "                    \n",
    "                    # if there are two parts, and there is no author name in the first,\n",
    "                    # part[0] is text and part[1] are footnotes\n",
    "                    if len(parts) == 2 and not one:\n",
    "                        print('2 parts found without author name', t_id)\n",
    "                        text = parts[0]\n",
    "                        fn = parts[1]\n",
    "                    # with author name, parts[0] is the author name, parts[1] is the text\n",
    "                    elif len(parts) == 2 and one:\n",
    "                        pass\n",
    "                        text = ''.join((parts[0], parts[1]))\n",
    "                    #    print('2 parts found with author name', t_id)\n",
    "                    \n",
    "                    # if there is one part, the text probably is a title (level 1 or level 2)\n",
    "                    if len(parts) == 1:\n",
    "                        #print('1 part found', t_id)\n",
    "                        if one:\n",
    "                            print('author name in title', t_id)\n",
    "                        text = parts[0]\n",
    "                        \n",
    "                    # author name should be kept in the text and put in the paratext file\n",
    "                    # parts with author name can be recognized by checking whether the text starts with الكاتب\n",
    "\n",
    "            elif e.tag == 'page':\n",
    "                page = e.text\n",
    "            elif e.tag == 'part':\n",
    "                part = e.text\n",
    "            #print(e.tag)\n",
    "        \n",
    "        # ignore entries that don't have text\n",
    "        if not text is None:\n",
    "            result[t_id] = {'text': text, 'page': page, 'part': part}\n",
    "        \n",
    "        if not fn is None:\n",
    "            result[t_id]['footnotes'] = fn\n",
    "\n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "book = read_book('/home/jvdzwaan/data/adh-corpora/dawa/New_xml_corpus/1/book.xml', 1)\n",
    "print(len(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split file 286 on level 1 (this file contains multiple journals)\n",
    "\n",
    "title_file = '/home/jvdzwaan/data/adh-corpora/dawa/New_xml_corpus/286/title.xml'\n",
    "book_file = '/home/jvdzwaan/data/adh-corpora/dawa/New_xml_corpus/286/book.xml'\n",
    "\n",
    "book = read_almanar(book_file, 286)\n",
    "print(len(book))\n",
    "title, levels = read_title(title_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine book and title\n",
    "# and write to file\n",
    "import codecs\n",
    "\n",
    "def write_almanar(book, title):\n",
    "    to_write = []\n",
    "    journal = []\n",
    "    notes_year = []\n",
    "    notes = []\n",
    "    first = True\n",
    "    for b_id, data in book.items():\n",
    "        text = data['text']\n",
    "        if b_id in title:\n",
    "            #print(b_id)\n",
    "            #print('title!')\n",
    "            #print(title[b_id])\n",
    "            # Sometimes the titles in the xml are in the wrong order\n",
    "            # So sort them to put them in the right order\n",
    "            title[b_id].sort(key=lambda t: int(t['level']))\n",
    "            #print(title[b_id])\n",
    "            #print('---')\n",
    "            for t in title[b_id]:\n",
    "                ti = t['title']\n",
    "                lvl = t['level']\n",
    "                \n",
    "                if lvl == '1':\n",
    "                    if not first:\n",
    "                        to_write.append(''.join(journal))\n",
    "                        notes_year.append(''.join(notes))\n",
    "                    else:\n",
    "                        first = False\n",
    "                    journal = []\n",
    "                    notes = []\n",
    "                    \n",
    "                \n",
    "                #print(title[b_id]['title'], title[b_id]['level'])\n",
    "                journal.append('### {} {}\\n'.format(int(lvl)*'|', ti))\n",
    "                    \n",
    "                # Remove the first occurence of the title string\n",
    "                text = text.replace(ti, '', 1)\n",
    "        journal.append(text.strip())\n",
    "        journal.append('\\n')\n",
    "        \n",
    "        fn = data.get('footnotes')\n",
    "        if fn is not None:\n",
    "            notes.append(fn)\n",
    "        \n",
    "        # sometimes the page marker information is incomplete (e.g. for book 12)\n",
    "        # in that case, we don't write the marker information\n",
    "        if not data['part'] is None and not data['page'] is None:\n",
    "            page = data['page'].split()[0]\n",
    "            part = data['part'].split()[0]\n",
    "                \n",
    "            try:\n",
    "                part = int(part)\n",
    "            except ValueError:\n",
    "                print('Invalid part {} ({})'.format(part, out_name))\n",
    "                part = 0\n",
    "                    \n",
    "            try:\n",
    "                page = int(page)\n",
    "            except ValueError:\n",
    "                print('Invalid page {} ({})'.format(page, out_name))\n",
    "                page = 0\n",
    "                \n",
    "            page_marker = 'V{:03}P{:04}'.format(part, page)\n",
    "            journal.append(page_marker)\n",
    "            journal.append('\\n')\n",
    "            #print('---')\n",
    "    print(len(to_write))\n",
    "    \n",
    "    # write text files\n",
    "    for i, text in enumerate(to_write):\n",
    "        out_file = '/home/jvdzwaan/data/adh-corpora/dawa/txt/286-{:03}.txt'.format(i)\n",
    "        print(out_file)\n",
    "        with open(out_file, 'w') as f:\n",
    "            f.write(text)\n",
    "            f.write('\\n')\n",
    "            \n",
    "    # write notes\n",
    "    for i, ns in enumerate(notes_year):\n",
    "        if ns != '':\n",
    "            out_file = os.path.join(notes_dir, '286-{:03}.txt'.format(i))\n",
    "            print(out_file)\n",
    "            with open(out_file, 'w') as f:\n",
    "                f.write(ns)\n",
    "                f.write('\\n')\n",
    "        \n",
    "\n",
    "write_almanar(book, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write almanar notes\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

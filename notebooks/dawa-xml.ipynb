{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from lxml import etree\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def read_book(fname, book_id):\n",
    "    result = OrderedDict()\n",
    "    regex = '__________\\n'\n",
    "    \n",
    "    # Extract the words\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('book'))\n",
    "    for event, elem in context:\n",
    "        for e in elem.iterchildren():\n",
    "            if e.tag == 'id':\n",
    "                t_id = e.text\n",
    "                #print(t_id)\n",
    "            elif e.tag == 'nass':   # text\n",
    "                # sometimes the text is None (e.g., file 16, id 214)\n",
    "                text = e.text\n",
    "                fn = None\n",
    "                if text is None:\n",
    "                    print('None text found in {} (prev? id: {})'.format(fname, t_id))\n",
    "                else:\n",
    "                    # &#xd; is automatically replaced by \\r, but we would like to have \\n\n",
    "                    text = text.replace('\\r', '\\n')\n",
    "                    \n",
    "                    # get the footnotes if they are there\n",
    "                    parts = re.split(regex, text)\n",
    "                    \n",
    "                    # we shouln't have parts longer than 2\n",
    "                    if len(parts) > 2:                        \n",
    "                        # all exceptions\n",
    "                        print('book_id', book_id)\n",
    "                        if book_id in (27, 38):\n",
    "                            text = parts[0]\n",
    "                            fn = regex.join(parts[1:])\n",
    "                        elif book_id in (36, 70, 89, 124, 140, 142, 143, 146, 147, 148):\n",
    "                            # seems to be a table of contents and/or index\n",
    "                            # so, put the \n",
    "                            text = ' '\n",
    "                            fn = text\n",
    "                        else:\n",
    "                            print('More parts found in {} ({})'.format(t_id, len(parts)))\n",
    "                            print(text)\n",
    "                            print('---')\n",
    "    \n",
    "                    if len(parts) == 2:\n",
    "                        t, fn = parts\n",
    "                        text = t\n",
    "\n",
    "            elif e.tag == 'page':\n",
    "                page = e.text\n",
    "            elif e.tag == 'part':\n",
    "                part = e.text\n",
    "            #print(e.tag)\n",
    "        \n",
    "        # ignore entries that don't have text\n",
    "        if not text is None:\n",
    "            result[t_id] = {'text': text, 'page': page, 'part': part}\n",
    "        \n",
    "        if not fn is None:\n",
    "            result[t_id]['footnotes'] = fn\n",
    "\n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "book = read_book('/home/jvdzwaan/data/adh-corpora/dawa/New_xml_corpus/1/book.xml', 1)\n",
    "print(len(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_title(fname):\n",
    "    result = {}\n",
    "    levels = {}\n",
    "    \n",
    "    # Extract the words\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('title'))\n",
    "    for event, elem in context:\n",
    "        for e in elem.iterchildren():\n",
    "            if e.tag == 'id':\n",
    "                t_id = e.text\n",
    "                #print(t_id)\n",
    "            elif e.tag == 'tit':\n",
    "                title = e.text\n",
    "                # &#xd; is automatically replaced by \\r, but we would like to have \\n\n",
    "                title = title.replace('\\r', '\\n')\n",
    "            elif e.tag == 'lvl':\n",
    "                level = e.text\n",
    "                levels[level] = None\n",
    "            #print(e.tag)\n",
    "        if not t_id in result.keys():\n",
    "            result[t_id] = []\n",
    "            \n",
    "        result[t_id].append({'title': title, 'level': level})\n",
    "\n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    \n",
    "    #print('levels found:', levels.keys())\n",
    "    return result, levels.keys()\n",
    "\n",
    "title, levels = read_title('/home/jvdzwaan/data/adh-corpora/dawa/New_xml_corpus/1/title.xml')\n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine book and title\n",
    "# and write to file\n",
    "import codecs\n",
    "\n",
    "def combine_data(book, title, out_file):\n",
    "    with codecs.open(out_file, 'w', encoding='utf-8') as f:\n",
    "        for b_id, data in book.items():\n",
    "            text = data['text']\n",
    "            if b_id in title:\n",
    "                #print(b_id)\n",
    "                #print('title!')\n",
    "                #print(title[b_id])\n",
    "                # Sometimes the titles in the xml are in the wrong order\n",
    "                # So sort them to put them in the right order\n",
    "                title[b_id].sort(key=lambda t: int(t['level']))\n",
    "                #print(title[b_id])\n",
    "                #print('---')\n",
    "                for t in title[b_id]:\n",
    "                    ti = t['title']\n",
    "                    lvl = t['level']\n",
    "                    #print(title[b_id]['title'], title[b_id]['level'])\n",
    "                    f.write('### {} {}\\n'.format(int(lvl)*'|', ti))\n",
    "                    #if text.strip().startswith(ti):\n",
    "                    #    print('title in text', b_id)\n",
    "                    #    text = text.replace(ti, '### {} {}\\n'.format(int(lvl)*'|', ti))\n",
    "                    #else:\n",
    "                    #    text = '### {} {}\\n'.format(int(lvl)*'|', ti) + text\n",
    "                    #    print('title text not found', b_id)\n",
    "                    \n",
    "                    # Remove the first occurence of the title string\n",
    "                    text = text.replace(ti, '', 1)\n",
    "            f.write(text.strip())\n",
    "            f.write('\\n')\n",
    "            # sometimes the page marker information is incomplete (e.g. for book 12)\n",
    "            # in that case, we don't write the marker information\n",
    "            if not data['part'] is None and not data['page'] is None:\n",
    "                page = data['page'].split()[0]\n",
    "                part = data['part'].split()[0]\n",
    "                \n",
    "                try:\n",
    "                    part = int(part)\n",
    "                except ValueError:\n",
    "                    print('Invalid part {} ({})'.format(part, out_name))\n",
    "                    part = 0\n",
    "                    \n",
    "                try:\n",
    "                    page = int(page)\n",
    "                except ValueError:\n",
    "                    print('Invalid page {} ({})'.format(page, out_name))\n",
    "                    page = 0\n",
    "                \n",
    "                page_marker = 'V{:03}P{:04}'.format(part, page)\n",
    "                f.write(page_marker)\n",
    "                f.write('\\n')\n",
    "            #print('---')\n",
    "combine_data(book, title, 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "in_dir = '/home/jvdzwaan/data/adh-corpora/dawa/New_xml_corpus/'\n",
    "out_dir = '/home/jvdzwaan/data/adh-corpora/dawa/txt/'\n",
    "\n",
    "level_data = []\n",
    "\n",
    "for i in tqdm(range(1, 217)):\n",
    "    out_name = '{}.txt'.format(i)\n",
    "    \n",
    "    d = os.path.join(in_dir, str(i))\n",
    "    book_file = os.path.join(d, 'book.xml')\n",
    "    title_file = os.path.join(d, 'title.xml')\n",
    "    #print(book_file)\n",
    "    #print(title_file)\n",
    "    book = read_book(book_file, i)\n",
    "    title, levels = read_title(title_file)\n",
    "    \n",
    "    level_data.append({'book': i, 'levels': list(levels)})\n",
    "    \n",
    "    # write txt to output file\n",
    "    out_file = os.path.join(out_dir, out_name)\n",
    "    print(out_file)\n",
    "    combine_data(book, title, out_file)\n",
    "    \n",
    "    # write notes, etc. to output file\n",
    "    notes = []\n",
    "    for b_id, data in book.items():\n",
    "        fn = data.get('footnotes')\n",
    "        if fn is not None:\n",
    "            notes.append(fn)\n",
    "        # TODO: save notest to file\n",
    "        #if len(notes) > 0:\n",
    "        #    out_file = ''\n",
    "        #    with codecs.open(out_file, 'w', encoding='utf-8') as f:\n",
    "        #        f.write('\\n'.join(notes))\n",
    "        #        f.write('\\n')\n",
    "                \n",
    "    print('-'*80)\n",
    "    \n",
    "levels = pd.DataFrame(level_data)\n",
    "levels = levels.set_index('book')\n",
    "levels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels.to_csv('dawa_levels.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the footnotes\n",
    "\n",
    "import re\n",
    "\n",
    "regex = '__________\\n'\n",
    "\n",
    "for b_id, data in book.items():\n",
    "    text = data['text']\n",
    "    \n",
    "    m = re.search(regex, text)\n",
    "    #if m:\n",
    "    #    print(b_id)\n",
    "        \n",
    "    parts = re.split(regex, text)\n",
    "    if len(parts) > 2:\n",
    "        print(b_id, len(parts))\n",
    "    \n",
    "    if len(parts) == 2:\n",
    "        t, fn = parts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

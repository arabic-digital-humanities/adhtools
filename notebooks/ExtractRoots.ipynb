{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the XML files\n",
    "def extract_from_xml(search_roots, filenames):\n",
    "    metadata = []\n",
    "    matched_words = []\n",
    "    for filename in filenames:\n",
    "        with open(filename) as fn:\n",
    "            xml_data = BeautifulSoup(fn, 'xml')\n",
    "            meta_dict = {meta['name']: meta.text.strip() for meta in xml_data.metadata.find_all('meta')}\n",
    "            #meta_dict['Bookname'] = dirname\n",
    "            #meta_dict['Filename'] = filename\n",
    "            metadata.append(meta_dict)\n",
    "\n",
    "            # loop over words and match with the searched words\n",
    "            # To do: do not include roots that are not within the search set\n",
    "            for word in xml_data.morphology_analysis.find_all('word'):\n",
    "                roots = set([a.get('root', '') for a in word.find_all('analysis')])\n",
    "                if not set(search_roots).isdisjoint(roots):\n",
    "                    matched_words.append((filename, word.attrs, [a.attrs for a in word.find_all('analysis')]))\n",
    "                    \n",
    "    # # Put all results in a dataframe\n",
    "    df_total = pd.DataFrame()\n",
    "    for filename, word_dict, analyses in matched_words:\n",
    "        df_analyses = pd.DataFrame(analyses)\n",
    "        df_analyses['Filename'] = os.path.basename(filename)\n",
    "        for att in word_dict:\n",
    "            df_analyses[att] = word_dict[att]\n",
    "        df_total = df_total.append(df_analyses)\n",
    "    return metadata, df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the csv files\n",
    "def extract_from_csv(search_roots, filenames):\n",
    "    df_total = pd.DataFrame()\n",
    "    for i in range(len(filenames)):\n",
    "        if i%1000==0:\n",
    "            print(i)\n",
    "        filename = filenames[i]\n",
    "        df_sub = pd.read_csv(filename, index_col=0)\n",
    "        df_sub = df_sub[df_sub.root.isin(search_roots)]\n",
    "        df_total = df_total.append(df_sub)\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses_roots = set('''سمع\n",
    "بصر\n",
    "لمس\n",
    "شمم\n",
    "ذوق'''.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from XML\n",
    "filepath = '/media/sf_VBox_Shared/Arabic/indices/20180424/merged/'\n",
    "xml_file_names = itertools.chain.from_iterable([[os.path.join(d, f) for f in fnames] for d, dnames, fnames in os.walk(filepath)])\n",
    "metadata, matched_words = extract_from_xml(senses_roots, list(xml_file_names)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from CSV\n",
    "filepath = '/media/sf_VBox_Shared/Arabic/Fiqh/Fiqh-Alkhalil-csv/csv'\n",
    "csv_file_names = [os.path.join(filepath, fn) for fn in os.listdir(filepath)]\n",
    "df_total = extract_from_csv(senses_roots, list(csv_file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['root'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses_dict = {\n",
    "    u'بصر': 'see',\n",
    "    u'سمع': 'hear',\n",
    "    u'لمس': 'touch',\n",
    "    u'شمم': 'smell',\n",
    "    u'ذوق': 'taste'\n",
    "}\n",
    "\n",
    "df_total['sense'] = [senses_dict[s] for s in df_total['root']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fields = ['BookURI', 'Century', 'AuthorNAME', 'AuthorGeographicalArea', 'AuthorBORNH', 'AuthorBORNC', 'AuthorDIEDH', 'AuthorDIEDC',  'BookSUBJ', 'NumberOfTokens']\n",
    "\n",
    "metadata_new = pd.read_csv('/media/sf_VBox_Shared/Arabic/Fiqh/merged_metadata.csv')\n",
    "\n",
    "metadata_new['Bookname'] = metadata_new.filename_old.str.extract('(.*)\\.txt', expand=False)\n",
    "\n",
    "#metadata_merged = metadata_df['Bookname'].reset_index().merge(metadata_new, left_on='Bookname', right_on='Bookname', how='left')\n",
    "metadata_merged = metadata_new[['Bookname']+metadata_fields].copy()\n",
    "\n",
    "metadata_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_total.merge(metadata_merged, left_on='title', right_on='Bookname', how='left').drop(['Bookname', 'title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('/media/sf_VBox_Shared/Arabic/Analyses/senses_fiqh.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dict = {s['root']: s['tr_root'] for i, s in df_total[['root', 'tr_root']].drop_duplicates().iterrows()}\n",
    "tr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also prepare aggregated csv\n",
    "df_agg = df_total.groupby(['title', 'sense']).size().unstack(fill_value=0)\n",
    "#df_agg.columns = [u'{} ({})'.format(c, tr_dict[c]) for c in df_agg.columns]\n",
    "\n",
    "df_agg_merged = df_agg.reset_index().merge(metadata_merged, left_on='title', right_on='Bookname', how='left').drop(['Bookname'], axis=1)\n",
    "\n",
    "senses_cols = df_agg.columns\n",
    "senses_cols_relative = [c+'_p' for c in df_agg.columns]\n",
    "df_agg_merged[senses_cols_relative] = df_agg_merged.apply(lambda r: r[senses_cols]/r['NumberOfTokens'], axis=1)\n",
    "\n",
    "df_agg_merged.to_csv('/media/sf_VBox_Shared/Arabic/Analyses/senses_fiqh_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
